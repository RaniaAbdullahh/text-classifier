{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'assets/amazon_cells_labelled.txt'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath_dict={'amazon':'assets/amazon_cells_labelled.txt',\n",
    "              'yelp':'assets/yelp_labelled.txt',\n",
    "             'imdb' :'assets/imdb_labelled.txt'}\n",
    "filepath_dict['amazon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('amazon', 'assets/amazon_cells_labelled.txt'), ('yelp', 'assets/yelp_labelled.txt'), ('imdb', 'assets/imdb_labelled.txt')])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath_dict.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for source, filepath in filepath_dict.items():\n",
    "    df=pd.read_csv(filepath,names=['sentence','label'],sep='\\t')\n",
    "    df['source']=source\n",
    "    df_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[                                              sentence  label  source\n",
       " 0    So there is no way for me to plug it in here i...      0  amazon\n",
       " 1                          Good case, Excellent value.      1  amazon\n",
       " 2                               Great for the jawbone.      1  amazon\n",
       " 3    Tied to charger for conversations lasting more...      0  amazon\n",
       " 4                                    The mic is great.      1  amazon\n",
       " ..                                                 ...    ...     ...\n",
       " 995  The screen does get smudged easily because it ...      0  amazon\n",
       " 996  What a piece of junk.. I lose more calls on th...      0  amazon\n",
       " 997                       Item Does Not Match Picture.      0  amazon\n",
       " 998  The only thing that disappoint me is the infra...      0  amazon\n",
       " 999  You can not answer calls with the unit, never ...      0  amazon\n",
       " \n",
       " [1000 rows x 3 columns],\n",
       "                                               sentence  label source\n",
       " 0                             Wow... Loved this place.      1   yelp\n",
       " 1                                   Crust is not good.      0   yelp\n",
       " 2            Not tasty and the texture was just nasty.      0   yelp\n",
       " 3    Stopped by during the late May bank holiday of...      1   yelp\n",
       " 4    The selection on the menu was great and so wer...      1   yelp\n",
       " ..                                                 ...    ...    ...\n",
       " 995  I think food should have flavor and texture an...      0   yelp\n",
       " 996                           Appetite instantly gone.      0   yelp\n",
       " 997  Overall I was not impressed and would not go b...      0   yelp\n",
       " 998  The whole experience was underwhelming, and I ...      0   yelp\n",
       " 999  Then, as if I hadn't wasted enough of my life ...      0   yelp\n",
       " \n",
       " [1000 rows x 3 columns],\n",
       "                                               sentence  label source\n",
       " 0    A very, very, very slow-moving, aimless movie ...      0   imdb\n",
       " 1    Not sure who was more lost - the flat characte...      0   imdb\n",
       " 2    Attempting artiness with black & white and cle...      0   imdb\n",
       " 3         Very little music or anything to speak of.        0   imdb\n",
       " 4    The best scene in the movie was when Gerardo i...      1   imdb\n",
       " ..                                                 ...    ...    ...\n",
       " 743  I just got bored watching Jessice Lange take h...      0   imdb\n",
       " 744  Unfortunately, any virtue in this film's produ...      0   imdb\n",
       " 745                   In a word, it is embarrassing.        0   imdb\n",
       " 746                               Exceptionally bad!        0   imdb\n",
       " 747  All in all its an insult to one's intelligence...      0   imdb\n",
       " \n",
       " [748 rows x 3 columns]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence    Great for the jawbone.\n",
       "label                            1\n",
       "source                      amazon\n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_list[0].iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ['John likes ice cream', 'John hates chocolate.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 1, 0, 1, 1],\n",
       "       [1, 1, 0, 1, 0, 0]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(min_df=0, lowercase=False)\n",
    "vectorizer.fit(sentences)\n",
    "vectorizer.vocabulary_    \n",
    "vectorizer.transform(sentences).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 1])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df_yelp=df_list[1]\n",
    "df_amazon=df_list[0]\n",
    "df_imdb=df_list[2]\n",
    "sentences = df_yelp['sentence'].values\n",
    "sentences_zero = df_amazon['sentence'].values\n",
    "sentences_two = df_imdb['sentence'].values\n",
    "y = df_yelp['label'].values\n",
    "y_zero= df_amazon['label'].values\n",
    "y_two=df_imdb['label'].values\n",
    "y[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yelp Accuracy: 0.772\n"
     ]
    }
   ],
   "source": [
    "sentences_train, sentences_test, y_train, y_test = train_test_split( sentences, y, test_size=0.25, random_state=1000)\n",
    "vectorizer.fit(sentences_train)\n",
    "X_train = vectorizer.transform(sentences_train)\n",
    "X_test  = vectorizer.transform(sentences_test)\n",
    "X_train\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier=LogisticRegression()\n",
    "classifier.fit(X_train,y_train)\n",
    "score=classifier.score(X_test,y_test)\n",
    "print(\"yelp Accuracy:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amazon Accuracy: 0.792\n"
     ]
    }
   ],
   "source": [
    "sentences_zero_train, sentences_zero_test, y_train_amazon, y_test_amazon = train_test_split( sentences_zero, y_zero, test_size=0.25, random_state=1000)\n",
    "vectorizer.fit(sentences_zero_train)\n",
    "X_train_amazon = vectorizer.transform(sentences_zero_train)\n",
    "X_test_amazon = vectorizer.transform(sentences_zero_test)\n",
    "X_train_amazon\n",
    "classifier.fit(X_train_amazon,y_train_amazon)\n",
    "score=classifier.score(X_test_amazon,y_test_amazon)\n",
    "print(\"amazon Accuracy:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_two_train, sentences_two_test, y_train_imdb, y_test_imdb = train_test_split( sentences_two, y_two, test_size=0.25, random_state=1000)\n",
    "vectorizer.fit(sentences_two_train)\n",
    "X_train_imdb = vectorizer.transform(sentences_two_train)\n",
    "X_test_imdb = vectorizer.transform(sentences_two_test)\n",
    "X_train_imdb\n",
    "classifier.fit(X_train_imdb,y_train_imdb)\n",
    "score=classifier.score(X_test_amazon,y_test_amazon)\n",
    "print(\"amazon Accuracy:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
